import { describe, it, expect } from 'vitest';
import request from 'supertest';
import { app } from '../../src/api/server';
import * as fs from 'fs';
import * as path from 'path';

// This test suite generates a single .txt file containing the full output
// of 10 conversational prompts for qualitative review.
describe('Conversational Showcase to File', () => {

    const PROMPTS = [
        "How many times in a week is a debt collector allowed to call me?",
        "I bought a used car from a dealer last week and the engine is already making weird noises. What are my rights?",
        "What if a telemarketer calls me really late at night, like after 10 PM?",
        "Can you explain what 'bait and switch' means in simple terms?",
        "How do I actually get telemarketers to stop calling my house?",
        "Tell me about the rules for getting a refund on something I bought.",
        "Is it legal for a car dealership to advertise a price and then add a bunch of mandatory fees at the end?",
        "My debt collector told my boss that I owe money. Are they allowed to do that?",
        "Can a store refuse to take back an item I bought on a 'final sale' clearance?",
        "I heard the government banned all non-compete agreements. Is that true?"
    ];

    it('should generate a .txt report with conversational responses and sources', async () => {
        
        // --- File Setup ---
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const reportDir = path.join(__dirname, '../../debug_output');
        const reportPath = path.join(reportDir, `CONVERSATIONAL_REPORT_${timestamp}.txt`);
        
        if (!fs.existsSync(reportDir)) {
            fs.mkdirSync(reportDir, { recursive: true });
        }

        let reportContent = `CONVERSATIONAL AI SHOWCASE REPORT\n`;
        reportContent += `Generated: ${new Date().toLocaleString()}\n\n`;

        console.log(`\nðŸš€ GENERATING CONVERSATIONAL REPORT...`);

        for (const [index, prompt] of PROMPTS.entries()) {
            console.log(`   Processing prompt ${index + 1}/${PROMPTS.length}: "${prompt.substring(0, 40)}..."`);
            
            const response = await request(app)
                .post('/api/v1/search')
                .send({ query: prompt });

            const data = response.body.data;
            const answer = data?.answer || "ERROR: No answer was generated by the API.";
            const contextNodes = data?.context?.ancestry || [];

            // --- Append to Report String ---
            reportContent += `=============================================================================\n`;
            reportContent += `  PROMPT ${index + 1}/${PROMPTS.length}\n`;
            reportContent += `=============================================================================\n\n`;
            reportContent += `ðŸ‘¤ USER ASKS:\n"${prompt}"\n\n`;

            reportContent += `ðŸ¤– CHATBOT RESPONDS:\n`;
            reportContent += `-----------------------------------------------------------------------------\n`;
            reportContent += `${answer}\n`;
            reportContent += `-----------------------------------------------------------------------------\n\n`;

            reportContent += `ðŸ“š SOURCE TEXTS USED BY AI:\n`;
            reportContent += `-----------------------------------------------------------------------------\n`;
            if (contextNodes.length > 0) {
                contextNodes.forEach((node: any) => {
                    reportContent += `[${node.urn}]\n`;
                    reportContent += `${node.content_text}\n\n`;
                });
            } else {
                reportContent += "No specific source texts were provided to the AI.\n\n";
            }
        }

        // --- Write Final Report ---
        fs.writeFileSync(reportPath, reportContent);
        console.log(`\nâœ… REPORT GENERATED: ${reportPath}`);

        expect(fs.existsSync(reportPath)).toBe(true);

    }, 240000); // 4 minute timeout for 10 sequential LLM calls and file I/O.
});